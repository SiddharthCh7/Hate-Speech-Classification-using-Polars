{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSBEvJCJxp5y",
    "outputId": "ac8ab7fe-3032-4972-ef4a-b3cad8927eb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV DataFrame:\n",
      "                                             Content  Label\n",
      "0  denial of normal the con be asked to comment o...      1\n",
      "1  just by being able to tweet this insufferable ...      1\n",
      "2  that is retarded you too cute to be single tha...      1\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from gensim.models import Word2Vec\n",
    "import json\n",
    "\n",
    "with open(r\"F:\\LPU\\Data\\Datasets\\Hate-Speech Classification\\hpc_batch\\keys.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "connection_string = data.get(\"Connection_string\")\n",
    "container_name = \"containerforregular\"\n",
    "csv_blob_name = \"HPC_NEW/HateSpeechDatasetBalanced.csv\"\n",
    "model_blob_name = \"HPC_NEW/word2vec.model\"\n",
    "vectors_blob_name = \"HPC_NEW/word2vec.model.wv.vectors.npy\"\n",
    "syn1_blob_name = \"HPC_NEW/word2vec.model.syn1neg.npy\"\n",
    "local_model_file = \"downloaded_model.model\"\n",
    "local_vectors_file = \"downloaded_model.model.wv.vectors.npy\"\n",
    "local_syn1_file = \"downloaded_model.model.syn1neg.npy\"\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "def download_blob_to_dataframe(blob_name):\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    download_stream = blob_client.download_blob()\n",
    "    df = pd.read_csv(download_stream)\n",
    "    return df\n",
    "\n",
    "df = download_blob_to_dataframe(csv_blob_name)\n",
    "print(\"CSV DataFrame:\")\n",
    "print(df.head(3))\n",
    "\n",
    "def download_blob_to_file(blob_name, local_file_path):\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    with open(local_file_path, \"wb\") as f:\n",
    "        download_stream = blob_client.download_blob()\n",
    "        f.write(download_stream.readall())\n",
    "\n",
    "download_blob_to_file(model_blob_name, local_model_file)\n",
    "download_blob_to_file(vectors_blob_name, local_vectors_file)\n",
    "download_blob_to_file(syn1_blob_name, local_syn1_file)\n",
    "\n",
    "model = Word2Vec.load(local_model_file)\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "df = pl.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "id": "w8z-UWGcsRke",
    "outputId": "a9672db5-caa5-46d4-8d34-9d2239c44a11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.dataframe.frame.DataFrame"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df.with_columns(pl.col('Content').str.to_lowercase())\n",
    "\n",
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (726_119, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Content</th><th>Label</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;denial&nbsp;of&nbsp;normal&nbsp;the&nbsp;con&nbsp;be&nbsp;as…</td><td>1</td></tr><tr><td>&quot;just&nbsp;by&nbsp;being&nbsp;able&nbsp;to&nbsp;tweet&nbsp;th…</td><td>1</td></tr><tr><td>&quot;that&nbsp;is&nbsp;retarded&nbsp;you&nbsp;too&nbsp;cute&nbsp;…</td><td>1</td></tr><tr><td>&quot;thought&nbsp;of&nbsp;a&nbsp;real&nbsp;badass&nbsp;mongo…</td><td>1</td></tr><tr><td>&quot;afro&nbsp;american&nbsp;basho&quot;</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;i&nbsp;mute&nbsp;this&nbsp;telecasting&nbsp;and&nbsp;pl…</td><td>1</td></tr><tr><td>&quot;but&nbsp;hell&nbsp;yeah&nbsp;he&nbsp;s&nbsp;not&nbsp;a&nbsp;bache…</td><td>1</td></tr><tr><td>&quot;great&nbsp;video&nbsp;musician&nbsp;but&nbsp;s&nbsp;not…</td><td>1</td></tr><tr><td>&quot;not&nbsp;great&nbsp;pop&nbsp;video&nbsp;yeah&nbsp;he&nbsp;s&nbsp;…</td><td>1</td></tr><tr><td>&quot;great&nbsp;video&nbsp;yeah&nbsp;he&nbsp;s&nbsp;non&nbsp;a&nbsp;pa…</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (726_119, 2)\n",
       "┌─────────────────────────────────┬───────┐\n",
       "│ Content                         ┆ Label │\n",
       "│ ---                             ┆ ---   │\n",
       "│ str                             ┆ i64   │\n",
       "╞═════════════════════════════════╪═══════╡\n",
       "│ denial of normal the con be as… ┆ 1     │\n",
       "│ just by being able to tweet th… ┆ 1     │\n",
       "│ that is retarded you too cute … ┆ 1     │\n",
       "│ thought of a real badass mongo… ┆ 1     │\n",
       "│ afro american basho             ┆ 1     │\n",
       "│ …                               ┆ …     │\n",
       "│ i mute this telecasting and pl… ┆ 1     │\n",
       "│ but hell yeah he s not a bache… ┆ 1     │\n",
       "│ great video musician but s not… ┆ 1     │\n",
       "│ not great pop video yeah he s … ┆ 1     │\n",
       "│ great video yeah he s non a pa… ┆ 1     │\n",
       "└─────────────────────────────────┴───────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUMIFmAIsRkf",
    "outputId": "4de3f7b3-4c1b-4d29-8b42-9bc1b671173c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\SIDDHARTH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SIDDHARTH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\SIDDHARTH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from typing import List\n",
    "import time\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "exception_words = {'no', 'not', 'never'}\n",
    "filtered_stopwords = stop_words - exception_words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_word(text):\n",
    "    words = text.split()\n",
    "    for x in range(len(words)):\n",
    "        words[x] = lemmatizer.lemmatize(words[x], pos='v')\n",
    "    return \" \".join(words)\n",
    "\n",
    "def remove_stopwords(text: str):\n",
    "    words = text.lower().split()\n",
    "    new_lst = []\n",
    "    for x in range(len(words)):\n",
    "        if words[x] not in filtered_stopwords:\n",
    "            new_lst.append(words[x])\n",
    "    del text\n",
    "    del words\n",
    "    return \" \".join(new_lst)\n",
    "\n",
    "\n",
    "def preprocess(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    start = time.time()\n",
    "    # xdf = df.lazy().with_columns(pl.col(\"Content\").str.to_lowercase().alias(\"Content\").str.split(by=' ').alias(\"Tokens_Content\"))\n",
    "\n",
    "    xdf = df.lazy().with_columns(\n",
    "        pl.col(\"Content\").map_elements(\n",
    "            remove_stopwords, return_dtype=pl.Utf8\n",
    "        ).alias(\"Stopwords_Content\")).with_columns(\n",
    "        pl.col(\"Stopwords_Content\").map_elements(\n",
    "            lemmatize_word, return_dtype=pl.Utf8\n",
    "        ).alias(\"Lemmatized_Content\")).collect()\n",
    "    end = time.time()\n",
    "    print(f\"Time taken : {(end-start):.3f}\")\n",
    "    xdf.drop_in_place(\"Stopwords_Content\")\n",
    "    return xdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gsd64HyUsRkg",
    "outputId": "9b736b0b-c811-4f71-8a16-51739ad7c291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken : 124.827\n"
     ]
    }
   ],
   "source": [
    "processed_df = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "OXNH1oks2x5J",
    "outputId": "a8af9dd8-b209-4468-bcf7-3a6214f84c13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (726_119, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Content</th><th>Label</th><th>Lemmatized_Content</th></tr><tr><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;denial&nbsp;of&nbsp;normal&nbsp;the&nbsp;con&nbsp;be&nbsp;as…</td><td>1</td><td>&quot;denial&nbsp;normal&nbsp;con&nbsp;ask&nbsp;comment&nbsp;…</td></tr><tr><td>&quot;just&nbsp;by&nbsp;being&nbsp;able&nbsp;to&nbsp;tweet&nbsp;th…</td><td>1</td><td>&quot;able&nbsp;tweet&nbsp;insufferable&nbsp;bullsh…</td></tr><tr><td>&quot;that&nbsp;is&nbsp;retarded&nbsp;you&nbsp;too&nbsp;cute&nbsp;…</td><td>1</td><td>&quot;retard&nbsp;cute&nbsp;single&nbsp;life&quot;</td></tr><tr><td>&quot;thought&nbsp;of&nbsp;a&nbsp;real&nbsp;badass&nbsp;mongo…</td><td>1</td><td>&quot;think&nbsp;real&nbsp;badass&nbsp;mongol&nbsp;style…</td></tr><tr><td>&quot;afro&nbsp;american&nbsp;basho&quot;</td><td>1</td><td>&quot;afro&nbsp;american&nbsp;basho&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;i&nbsp;mute&nbsp;this&nbsp;telecasting&nbsp;and&nbsp;pl…</td><td>1</td><td>&quot;mute&nbsp;telecast&nbsp;play&nbsp;kanye&nbsp;west&nbsp;…</td></tr><tr><td>&quot;but&nbsp;hell&nbsp;yeah&nbsp;he&nbsp;s&nbsp;not&nbsp;a&nbsp;bache…</td><td>1</td><td>&quot;hell&nbsp;yeah&nbsp;not&nbsp;bachelor&nbsp;loooooo…</td></tr><tr><td>&quot;great&nbsp;video&nbsp;musician&nbsp;but&nbsp;s&nbsp;not…</td><td>1</td><td>&quot;great&nbsp;video&nbsp;musician&nbsp;not&nbsp;music…</td></tr><tr><td>&quot;not&nbsp;great&nbsp;pop&nbsp;video&nbsp;yeah&nbsp;he&nbsp;s&nbsp;…</td><td>1</td><td>&quot;not&nbsp;great&nbsp;pop&nbsp;video&nbsp;yeah&nbsp;not&nbsp;p…</td></tr><tr><td>&quot;great&nbsp;video&nbsp;yeah&nbsp;he&nbsp;s&nbsp;non&nbsp;a&nbsp;pa…</td><td>1</td><td>&quot;great&nbsp;video&nbsp;yeah&nbsp;non&nbsp;paedophil…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (726_119, 3)\n",
       "┌─────────────────────────────────┬───────┬─────────────────────────────────┐\n",
       "│ Content                         ┆ Label ┆ Lemmatized_Content              │\n",
       "│ ---                             ┆ ---   ┆ ---                             │\n",
       "│ str                             ┆ i64   ┆ str                             │\n",
       "╞═════════════════════════════════╪═══════╪═════════════════════════════════╡\n",
       "│ denial of normal the con be as… ┆ 1     ┆ denial normal con ask comment … │\n",
       "│ just by being able to tweet th… ┆ 1     ┆ able tweet insufferable bullsh… │\n",
       "│ that is retarded you too cute … ┆ 1     ┆ retard cute single life         │\n",
       "│ thought of a real badass mongo… ┆ 1     ┆ think real badass mongol style… │\n",
       "│ afro american basho             ┆ 1     ┆ afro american basho             │\n",
       "│ …                               ┆ …     ┆ …                               │\n",
       "│ i mute this telecasting and pl… ┆ 1     ┆ mute telecast play kanye west … │\n",
       "│ but hell yeah he s not a bache… ┆ 1     ┆ hell yeah not bachelor loooooo… │\n",
       "│ great video musician but s not… ┆ 1     ┆ great video musician not music… │\n",
       "│ not great pop video yeah he s … ┆ 1     ┆ not great pop video yeah not p… │\n",
       "│ great video yeah he s non a pa… ┆ 1     ┆ great video yeah non paedophil… │\n",
       "└─────────────────────────────────┴───────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xcGom43esRkh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "vector_size = model.vector_size\n",
    "vocab = set(model.wv.index_to_key)\n",
    "\n",
    "def embed_word(text, vector_size=vector_size, vocab=vocab):\n",
    "    words = text.split()\n",
    "    embeddings = [\n",
    "        (model.wv[word].astype(np.float32) if word in vocab else np.zeros(vector_size, dtype=np.float32))\n",
    "        for word in words\n",
    "    ]\n",
    "    del vector_size\n",
    "    del vocab\n",
    "    \n",
    "    return np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfHKoniNhWRe",
    "outputId": "fd49d1b2-c13c-4f07-817a-3a30a679711b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'Content': String, 'Label': Int64, 'Lemmatized_Content': String, 'Vector_Content': Array(Float32, shape=(300,))})\n",
      "Schema({'Content': String, 'Label': Int64, 'Lemmatized_Content': String, 'Vector_Content': List(Float32)})\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "schema = {\n",
    "    'Content': pl.Utf8,\n",
    "    'Label': pl.Int64,\n",
    "    'Lemmatized_Content' : pl.Utf8,\n",
    "    'Vector_Content': (pl.List(pl.Float32))\n",
    "}\n",
    "\n",
    "initial_data = {\n",
    "    'Content': [\"sample text\"],\n",
    "    'Label': [1],\n",
    "    'Lemmatized_Content' : [\"Lemmatized this\"],\n",
    "    'Vector_Content': [embed_word(\"This is text\")]\n",
    "}\n",
    "\n",
    "df2 = pl.DataFrame(initial_data)\n",
    "print(df2.schema)\n",
    "\n",
    "def r_arr(lst):\n",
    "    arr = np.array(lst, dtype=np.float32)\n",
    "    if arr.shape != (300,):\n",
    "        raise ValueError(f\"Expected shape (300,), got {arr.shape}\")\n",
    "    return arr.ravel().tolist()\n",
    "\n",
    "struct_schema = pl.List(pl.Float32)\n",
    "df2 = df2.with_columns(\n",
    "    pl.col(\"Vector_Content\").cast(struct_schema)\n",
    ")\n",
    "\n",
    "empty_df = df2.slice(0,0)\n",
    "print(empty_df.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "z_vuqyQioGfs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5549"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (10, 3)\n",
      "┌─────────────────────────────────┬───────┬─────────────────────────────────┐\n",
      "│ Content                         ┆ Label ┆ Lemmatized_Content              │\n",
      "│ ---                             ┆ ---   ┆ ---                             │\n",
      "│ str                             ┆ i64   ┆ str                             │\n",
      "╞═════════════════════════════════╪═══════╪═════════════════════════════════╡\n",
      "│ denial of normal the con be as… ┆ 1     ┆ denial normal con ask comment … │\n",
      "│ just by being able to tweet th… ┆ 1     ┆ able tweet insufferable bullsh… │\n",
      "│ that is retarded you too cute … ┆ 1     ┆ retard cute single life         │\n",
      "│ thought of a real badass mongo… ┆ 1     ┆ think real badass mongol style… │\n",
      "│ afro american basho             ┆ 1     ┆ afro american basho             │\n",
      "│ yeah retard haha                ┆ 1     ┆ yeah retard haha                │\n",
      "│ the ching chong chung stuff     ┆ 1     ┆ ching chong chung stuff         │\n",
      "│ the dead what a slut still war… ┆ 1     ┆ dead slut still warm tweet slu… │\n",
      "│ let your tweets be harmless it… ┆ 1     ┆ let tweet harmless not affect … │\n",
      "│ these latinos who have a probl… ┆ 1     ┆ latinos problem immigration en… │\n",
      "└─────────────────────────────────┴───────┴─────────────────────────────────┘\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Content</th><th>Label</th><th>Lemmatized_Content</th><th>Vector_Content</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>list[f32]</td></tr></thead><tbody><tr><td>&quot;denial&nbsp;of&nbsp;normal&nbsp;the&nbsp;con&nbsp;be&nbsp;as…</td><td>1</td><td>&quot;denial&nbsp;normal&nbsp;con&nbsp;ask&nbsp;comment&nbsp;…</td><td>[-0.599104,&nbsp;0.147318,&nbsp;…&nbsp;0.10057]</td></tr><tr><td>&quot;just&nbsp;by&nbsp;being&nbsp;able&nbsp;to&nbsp;tweet&nbsp;th…</td><td>1</td><td>&quot;able&nbsp;tweet&nbsp;insufferable&nbsp;bullsh…</td><td>[0.103355,&nbsp;-0.24982,&nbsp;…&nbsp;-0.522497]</td></tr><tr><td>&quot;that&nbsp;is&nbsp;retarded&nbsp;you&nbsp;too&nbsp;cute&nbsp;…</td><td>1</td><td>&quot;retard&nbsp;cute&nbsp;single&nbsp;life&quot;</td><td>[-0.758037,&nbsp;0.818828,&nbsp;…&nbsp;-0.800236]</td></tr><tr><td>&quot;thought&nbsp;of&nbsp;a&nbsp;real&nbsp;badass&nbsp;mongo…</td><td>1</td><td>&quot;think&nbsp;real&nbsp;badass&nbsp;mongol&nbsp;style…</td><td>[-0.223098,&nbsp;-0.119148,&nbsp;…&nbsp;-0.776917]</td></tr><tr><td>&quot;afro&nbsp;american&nbsp;basho&quot;</td><td>1</td><td>&quot;afro&nbsp;american&nbsp;basho&quot;</td><td>[-0.515654,&nbsp;-0.600841,&nbsp;…&nbsp;-1.346117]</td></tr><tr><td>&quot;yeah&nbsp;retard&nbsp;haha&quot;</td><td>1</td><td>&quot;yeah&nbsp;retard&nbsp;haha&quot;</td><td>[-1.344133,&nbsp;1.072287,&nbsp;…&nbsp;-0.099435]</td></tr><tr><td>&quot;the&nbsp;ching&nbsp;chong&nbsp;chung&nbsp;stuff&quot;</td><td>1</td><td>&quot;ching&nbsp;chong&nbsp;chung&nbsp;stuff&quot;</td><td>[-0.016628,&nbsp;0.911098,&nbsp;…&nbsp;-0.302072]</td></tr><tr><td>&quot;the&nbsp;dead&nbsp;what&nbsp;a&nbsp;slut&nbsp;still&nbsp;war…</td><td>1</td><td>&quot;dead&nbsp;slut&nbsp;still&nbsp;warm&nbsp;tweet&nbsp;slu…</td><td>[-0.091936,&nbsp;-0.212315,&nbsp;…&nbsp;-0.171015]</td></tr><tr><td>&quot;let&nbsp;your&nbsp;tweets&nbsp;be&nbsp;harmless&nbsp;it…</td><td>1</td><td>&quot;let&nbsp;tweet&nbsp;harmless&nbsp;not&nbsp;affect&nbsp;…</td><td>[-0.487004,&nbsp;0.735953,&nbsp;…&nbsp;-0.426335]</td></tr><tr><td>&quot;these&nbsp;latinos&nbsp;who&nbsp;have&nbsp;a&nbsp;probl…</td><td>1</td><td>&quot;latinos&nbsp;problem&nbsp;immigration&nbsp;en…</td><td>[-0.129183,&nbsp;-0.144467,&nbsp;…&nbsp;-0.255399]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 4)\n",
       "┌───────────────────────────────┬───────┬───────────────────────────────┬──────────────────────────┐\n",
       "│ Content                       ┆ Label ┆ Lemmatized_Content            ┆ Vector_Content           │\n",
       "│ ---                           ┆ ---   ┆ ---                           ┆ ---                      │\n",
       "│ str                           ┆ i64   ┆ str                           ┆ list[f32]                │\n",
       "╞═══════════════════════════════╪═══════╪═══════════════════════════════╪══════════════════════════╡\n",
       "│ denial of normal the con be   ┆ 1     ┆ denial normal con ask comment ┆ [-0.599104, 0.147318, …  │\n",
       "│ as…                           ┆       ┆ …                             ┆ 0.1005…                  │\n",
       "│ just by being able to tweet   ┆ 1     ┆ able tweet insufferable       ┆ [0.103355, -0.24982, …   │\n",
       "│ th…                           ┆       ┆ bullsh…                       ┆ -0.5224…                 │\n",
       "│ that is retarded you too cute ┆ 1     ┆ retard cute single life       ┆ [-0.758037, 0.818828, …  │\n",
       "│ …                             ┆       ┆                               ┆ -0.800…                  │\n",
       "│ thought of a real badass      ┆ 1     ┆ think real badass mongol      ┆ [-0.223098, -0.119148, … │\n",
       "│ mongo…                        ┆       ┆ style…                        ┆ -0.77…                   │\n",
       "│ afro american basho           ┆ 1     ┆ afro american basho           ┆ [-0.515654, -0.600841, … │\n",
       "│                               ┆       ┆                               ┆ -1.34…                   │\n",
       "│ yeah retard haha              ┆ 1     ┆ yeah retard haha              ┆ [-1.344133, 1.072287, …  │\n",
       "│                               ┆       ┆                               ┆ -0.099…                  │\n",
       "│ the ching chong chung stuff   ┆ 1     ┆ ching chong chung stuff       ┆ [-0.016628, 0.911098, …  │\n",
       "│                               ┆       ┆                               ┆ -0.302…                  │\n",
       "│ the dead what a slut still    ┆ 1     ┆ dead slut still warm tweet    ┆ [-0.091936, -0.212315, … │\n",
       "│ war…                          ┆       ┆ slu…                          ┆ -0.17…                   │\n",
       "│ let your tweets be harmless   ┆ 1     ┆ let tweet harmless not affect ┆ [-0.487004, 0.735953, …  │\n",
       "│ it…                           ┆       ┆ …                             ┆ -0.426…                  │\n",
       "│ these latinos who have a      ┆ 1     ┆ latinos problem immigration   ┆ [-0.129183, -0.144467, … │\n",
       "│ probl…                        ┆       ┆ en…                           ┆ -0.25…                   │\n",
       "└───────────────────────────────┴───────┴───────────────────────────────┴──────────────────────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embed_word_fixed(text):\n",
    "    embedded = embed_word(text)  # Your original embedding function\n",
    "    # Convert to numpy array with explicit float32 type\n",
    "    arr = np.array(embedded, dtype=np.float32)\n",
    "    # Ensure it's exactly 300 dimensions\n",
    "    if arr.shape != (300,):\n",
    "        raise ValueError(f\"Expected shape (300,), got {arr.shape}\")\n",
    "    # Return the raw array values as a fixed-size list\n",
    "    return arr.ravel().tolist()\n",
    "\n",
    "asd = processed_df.slice(0,10)\n",
    "print(asd)\n",
    "asd = (asd\n",
    "    .with_columns(\n",
    "        pl.col(\"Lemmatized_Content\")\n",
    "        .map_elements(embed_word_fixed, return_dtype=pl.List(pl.Float32))\n",
    "        .alias(\"Vector_Content\")\n",
    "    )\n",
    ")\n",
    "\n",
    "asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "67Pg_owssRkj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before batch processing - Memory Usage: 50.9%\n",
      "Before batch 1 - Memory Usage: 50.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SIDDHARTH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\SIDDHARTH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After processing batch 1 - Memory Usage: 51.7%\n",
      "After garbage collection for batch 1 - Memory Usage: 51.7%\n",
      "Round 1 processed\n",
      "Before batch 2 - Memory Usage: 51.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SIDDHARTH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\SIDDHARTH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After processing batch 2 - Memory Usage: 52.4%\n",
      "After garbage collection for batch 2 - Memory Usage: 52.5%\n",
      "Round 2 processed\n",
      "Before batch 3 - Memory Usage: 52.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SIDDHARTH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\SIDDHARTH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After processing batch 3 - Memory Usage: 53.5%\n",
      "After garbage collection for batch 3 - Memory Usage: 53.6%\n",
      "Round 3 processed\n",
      "Before batch 4 - Memory Usage: 53.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SIDDHARTH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\SIDDHARTH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After processing batch 4 - Memory Usage: 55.1%\n",
      "After garbage collection for batch 4 - Memory Usage: 55.1%\n",
      "Round 4 processed\n",
      "Before batch 5 - Memory Usage: 55.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SIDDHARTH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\SIDDHARTH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After processing batch 5 - Memory Usage: 56.2%\n",
      "After garbage collection for batch 5 - Memory Usage: 56.2%\n",
      "Round 5 processed\n",
      "After all batches processed - Memory Usage: 56.2%\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import psutil\n",
    "import polars as pl\n",
    "\n",
    "def print_memory_usage(message=\"\"):\n",
    "    memory = psutil.virtual_memory().percent\n",
    "    print(f\"{message} - Memory Usage: {memory}%\")\n",
    "\n",
    "batch_size = len(processed_df) // 5\n",
    "\n",
    "print_memory_usage(\"Before batch processing\")\n",
    "\n",
    "for i in range(5):\n",
    "    print_memory_usage(f\"Before batch {i+1}\")\n",
    "\n",
    "    cdf = processed_df.slice(batch_size*i, batch_size)\n",
    "    x = (cdf.lazy()\n",
    "         .with_columns(pl.col(\"Lemmatized_Content\")\n",
    "                       .map_elements(embed_word_fixed, return_dtype=(pl.List(pl.Float32)))\n",
    "                       .alias(\"Vector_Content\"))\n",
    "         .collect())\n",
    "    empty_df.vstack(x, in_place=True)\n",
    "    print_memory_usage(f\"After processing batch {i+1}\")\n",
    "    del cdf\n",
    "    del x\n",
    "    gc.collect()\n",
    "\n",
    "    print_memory_usage(f\"After garbage collection for batch {i+1}\")\n",
    "    print(f'Round {i+1} processed')\n",
    "gc.collect()\n",
    "print_memory_usage(\"After all batches processed\")\n",
    "\n",
    "\n",
    "if len(empty_df) < len(processed_df):\n",
    "    cdf = processed_df.slice(batch_size * 5, len(processed_df) % 5)\n",
    "    x = (cdf.lazy()\n",
    "         .with_columns(pl.col(\"Lemmatized_Content\")\n",
    "                       .map_elements(embed_word_fixed, return_dtype=(pl.List(pl.Float32)))\n",
    "                       .alias(\"Vector_Content\"))\n",
    "         .collect())\n",
    "\n",
    "    empty_df.vstack(x, in_place=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_df[\"Vector_Content\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null(lst):\n",
    "    lst = lst.to_list()\n",
    "    return 1 if np.sum(lst, axis=0) == 0 else 0\n",
    "\n",
    "empty_df = empty_df.with_columns(pl.col(\"Vector_Content\").map_elements(check_null, return_dtype=pl.Int32).alias(\"is_null\"))\n",
    "empty_df = empty_df.filter(pl.col(\"is_null\") == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (725_129, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Label</th><th>Vector_Content</th><th>is_null</th></tr><tr><td>i64</td><td>list[f32]</td><td>i32</td></tr></thead><tbody><tr><td>1</td><td>[-0.599104,&nbsp;0.147318,&nbsp;…&nbsp;0.10057]</td><td>0</td></tr><tr><td>1</td><td>[0.103355,&nbsp;-0.24982,&nbsp;…&nbsp;-0.522497]</td><td>0</td></tr><tr><td>1</td><td>[-0.758037,&nbsp;0.818828,&nbsp;…&nbsp;-0.800236]</td><td>0</td></tr><tr><td>1</td><td>[-0.223098,&nbsp;-0.119148,&nbsp;…&nbsp;-0.776917]</td><td>0</td></tr><tr><td>1</td><td>[-0.515654,&nbsp;-0.600841,&nbsp;…&nbsp;-1.346117]</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1</td><td>[-0.132157,&nbsp;0.292088,&nbsp;…&nbsp;-0.136933]</td><td>0</td></tr><tr><td>1</td><td>[-0.178919,&nbsp;0.448879,&nbsp;…&nbsp;-0.381659]</td><td>0</td></tr><tr><td>1</td><td>[0.014921,&nbsp;0.239474,&nbsp;…&nbsp;-0.011825]</td><td>0</td></tr><tr><td>1</td><td>[-0.496958,&nbsp;0.37257,&nbsp;…&nbsp;-0.330948]</td><td>0</td></tr><tr><td>1</td><td>[-0.052785,&nbsp;0.215502,&nbsp;…&nbsp;-0.112516]</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (725_129, 3)\n",
       "┌───────┬─────────────────────────────────┬─────────┐\n",
       "│ Label ┆ Vector_Content                  ┆ is_null │\n",
       "│ ---   ┆ ---                             ┆ ---     │\n",
       "│ i64   ┆ list[f32]                       ┆ i32     │\n",
       "╞═══════╪═════════════════════════════════╪═════════╡\n",
       "│ 1     ┆ [-0.599104, 0.147318, … 0.1005… ┆ 0       │\n",
       "│ 1     ┆ [0.103355, -0.24982, … -0.5224… ┆ 0       │\n",
       "│ 1     ┆ [-0.758037, 0.818828, … -0.800… ┆ 0       │\n",
       "│ 1     ┆ [-0.223098, -0.119148, … -0.77… ┆ 0       │\n",
       "│ 1     ┆ [-0.515654, -0.600841, … -1.34… ┆ 0       │\n",
       "│ …     ┆ …                               ┆ …       │\n",
       "│ 1     ┆ [-0.132157, 0.292088, … -0.136… ┆ 0       │\n",
       "│ 1     ┆ [-0.178919, 0.448879, … -0.381… ┆ 0       │\n",
       "│ 1     ┆ [0.014921, 0.239474, … -0.0118… ┆ 0       │\n",
       "│ 1     ┆ [-0.496958, 0.37257, … -0.3309… ┆ 0       │\n",
       "│ 1     ┆ [-0.052785, 0.215502, … -0.112… ┆ 0       │\n",
       "└───────┴─────────────────────────────────┴─────────┘"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = empty_df.select(pl.col([\"Vector_Content\", \"Label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "path : pathlib.Path = r\"F:\\LPU\\Data\\Datasets\\Hate-Speech Classification\\hpc_batch\\final_df\\vectorized_df_v1.parquet\"\n",
    "\n",
    "final_df.write_parquet(path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File vectorized_df.parquet uploaded to container containerforregular/Parquet Files.\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "with open(\"keys.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "connection_string = data.get(\"Connection_string\")\n",
    "container_name = \"containerforregular/Parquet Files\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "import os\n",
    "local_file_path : pathlib.Path = \"embeddings_v1.parquet\"\n",
    "blob_name = os.path.basename(local_file_path)\n",
    "\n",
    "blob_client = container_client.get_blob_client(blob_name)\n",
    "\n",
    "with open(local_file_path, \"rb\") as data:\n",
    "    blob_client.upload_blob(data, overwrite=False)\n",
    "\n",
    "print(f\"File {blob_name} uploaded to container {container_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
