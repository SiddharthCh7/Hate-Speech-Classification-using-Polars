{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSBEvJCJxp5y",
    "outputId": "ac8ab7fe-3032-4972-ef4a-b3cad8927eb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV DataFrame:\n",
      "                                             Content  Label\n",
      "0  denial of normal the con be asked to comment o...      1\n",
      "1  just by being able to tweet this insufferable ...      1\n",
      "2  that is retarded you too cute to be single tha...      1\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from gensim.models import Word2Vec\n",
    "import json\n",
    "\n",
    "with open(\"keys.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "connection_string = data.get(\"Connection_string\")\n",
    "container_name = \"containerforregular\"\n",
    "csv_blob_name = \"HPC_NEW/HateSpeechDatasetBalanced.csv\"\n",
    "model_blob_name = \"HPC_NEW/word2vec.model\"\n",
    "vectors_blob_name = \"HPC_NEW/word2vec.model.wv.vectors.npy\"\n",
    "syn1_blob_name = \"HPC_NEW/word2vec.model.syn1neg.npy\"\n",
    "local_model_file = \"downloaded_model.model\"\n",
    "local_vectors_file = \"downloaded_model.model.wv.vectors.npy\"\n",
    "local_syn1_file = \"downloaded_model.model.syn1neg.npy\"\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "def download_blob_to_dataframe(blob_name):\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    download_stream = blob_client.download_blob()\n",
    "    df = pd.read_csv(download_stream)\n",
    "    return df\n",
    "\n",
    "df = download_blob_to_dataframe(csv_blob_name)\n",
    "print(\"CSV DataFrame:\")\n",
    "print(df.head(3))\n",
    "\n",
    "def download_blob_to_file(blob_name, local_file_path):\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    with open(local_file_path, \"wb\") as f:\n",
    "        download_stream = blob_client.download_blob()\n",
    "        f.write(download_stream.readall())\n",
    "\n",
    "download_blob_to_file(model_blob_name, local_model_file)\n",
    "download_blob_to_file(vectors_blob_name, local_vectors_file)\n",
    "download_blob_to_file(syn1_blob_name, local_syn1_file)\n",
    "\n",
    "model = Word2Vec.load(local_model_file)\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "df = pl.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "id": "w8z-UWGcsRke",
    "outputId": "a9672db5-caa5-46d4-8d34-9d2239c44a11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.dataframe.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df.with_columns(pl.col('Content').str.to_lowercase())\n",
    "\n",
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUMIFmAIsRkf",
    "outputId": "4de3f7b3-4c1b-4d29-8b42-9bc1b671173c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\SIDDHARTH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SIDDHARTH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\SIDDHARTH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from typing import List\n",
    "import time\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "exception_words = {'no', 'not', 'never'}\n",
    "filtered_stopwords = stop_words - exception_words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_word(text):\n",
    "    return [lemmatizer.lemmatize(word, pos=\"v\") for word in text]\n",
    "\n",
    "def remove_stopwords(text: str):\n",
    "    return [word for word in text if word not in filtered_stopwords]\n",
    "\n",
    "\n",
    "def preprocess(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    start = time.time()\n",
    "    xdf = df.lazy().with_columns(pl.col(\"Content\").str.to_lowercase().alias(\"Content\").str.split(by=' ').alias(\"Tokens_Content\"))\n",
    "\n",
    "    xdf = xdf.with_columns(\n",
    "        pl.col(\"Tokens_Content\").map_elements(\n",
    "            lambda batch: [\n",
    "                lemmatizer.lemmatize(word, pos=\"v\")\n",
    "                for word in batch\n",
    "                if word not in filtered_stopwords and not word.isdigit()\n",
    "            ],\n",
    "            return_dtype=pl.List(pl.Utf8)\n",
    "        ).alias(\"Processed_Content\")).collect()\n",
    "    end = time.time()\n",
    "    print(f\"Time taken : {(end-start):.3f}\")\n",
    "    return xdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gsd64HyUsRkg",
    "outputId": "9b736b0b-c811-4f71-8a16-51739ad7c291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken : 156.791\n"
     ]
    }
   ],
   "source": [
    "processed_df = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "OXNH1oks2x5J",
    "outputId": "a8af9dd8-b209-4468-bcf7-3a6214f84c13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (726_119, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Content</th><th>Label</th><th>Tokens_Content</th><th>Processed_Content</th></tr><tr><td>str</td><td>i64</td><td>list[str]</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;denial&nbsp;of&nbsp;normal&nbsp;the&nbsp;con&nbsp;be&nbsp;as…</td><td>1</td><td>[&quot;denial&quot;,&nbsp;&quot;of&quot;,&nbsp;…&nbsp;&quot;retard&quot;]</td><td>[&quot;denial&quot;,&nbsp;&quot;normal&quot;,&nbsp;…&nbsp;&quot;retard&quot;]</td></tr><tr><td>&quot;just&nbsp;by&nbsp;being&nbsp;able&nbsp;to&nbsp;tweet&nbsp;th…</td><td>1</td><td>[&quot;just&quot;,&nbsp;&quot;by&quot;,&nbsp;…&nbsp;&quot;vagina&quot;]</td><td>[&quot;able&quot;,&nbsp;&quot;tweet&quot;,&nbsp;…&nbsp;&quot;vagina&quot;]</td></tr><tr><td>&quot;that&nbsp;is&nbsp;retarded&nbsp;you&nbsp;too&nbsp;cute&nbsp;…</td><td>1</td><td>[&quot;that&quot;,&nbsp;&quot;is&quot;,&nbsp;…&nbsp;&quot;life&quot;]</td><td>[&quot;retard&quot;,&nbsp;&quot;cute&quot;,&nbsp;…&nbsp;&quot;life&quot;]</td></tr><tr><td>&quot;thought&nbsp;of&nbsp;a&nbsp;real&nbsp;badass&nbsp;mongo…</td><td>1</td><td>[&quot;thought&quot;,&nbsp;&quot;of&quot;,&nbsp;…&nbsp;&quot;be&quot;]</td><td>[&quot;think&quot;,&nbsp;&quot;real&quot;,&nbsp;…&nbsp;&quot;soon&quot;]</td></tr><tr><td>&quot;afro&nbsp;american&nbsp;basho&quot;</td><td>1</td><td>[&quot;afro&quot;,&nbsp;&quot;american&quot;,&nbsp;&quot;basho&quot;]</td><td>[&quot;afro&quot;,&nbsp;&quot;american&quot;,&nbsp;&quot;basho&quot;]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;i&nbsp;mute&nbsp;this&nbsp;telecasting&nbsp;and&nbsp;pl…</td><td>1</td><td>[&quot;i&quot;,&nbsp;&quot;mute&quot;,&nbsp;…&nbsp;&quot;cunt&quot;]</td><td>[&quot;mute&quot;,&nbsp;&quot;telecast&quot;,&nbsp;…&nbsp;&quot;cunt&quot;]</td></tr><tr><td>&quot;but&nbsp;hell&nbsp;yeah&nbsp;he&nbsp;s&nbsp;not&nbsp;a&nbsp;bache…</td><td>1</td><td>[&quot;but&quot;,&nbsp;&quot;hell&quot;,&nbsp;…&nbsp;&quot;singer&quot;]</td><td>[&quot;hell&quot;,&nbsp;&quot;yeah&quot;,&nbsp;…&nbsp;&quot;singer&quot;]</td></tr><tr><td>&quot;great&nbsp;video&nbsp;musician&nbsp;but&nbsp;s&nbsp;not…</td><td>1</td><td>[&quot;great&quot;,&nbsp;&quot;video&quot;,&nbsp;…&nbsp;&quot;professional&quot;]</td><td>[&quot;great&quot;,&nbsp;&quot;video&quot;,&nbsp;…&nbsp;&quot;professional&quot;]</td></tr><tr><td>&quot;not&nbsp;great&nbsp;pop&nbsp;video&nbsp;yeah&nbsp;he&nbsp;s&nbsp;…</td><td>1</td><td>[&quot;not&quot;,&nbsp;&quot;great&quot;,&nbsp;…&nbsp;&quot;singer&quot;]</td><td>[&quot;not&quot;,&nbsp;&quot;great&quot;,&nbsp;…&nbsp;&quot;singer&quot;]</td></tr><tr><td>&quot;great&nbsp;video&nbsp;yeah&nbsp;he&nbsp;s&nbsp;non&nbsp;a&nbsp;pa…</td><td>1</td><td>[&quot;great&quot;,&nbsp;&quot;video&quot;,&nbsp;…&nbsp;&quot;singer&quot;]</td><td>[&quot;great&quot;,&nbsp;&quot;video&quot;,&nbsp;…&nbsp;&quot;singer&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (726_119, 4)\n",
       "┌──────────────────────────────┬───────┬─────────────────────────────┬─────────────────────────────┐\n",
       "│ Content                      ┆ Label ┆ Tokens_Content              ┆ Processed_Content           │\n",
       "│ ---                          ┆ ---   ┆ ---                         ┆ ---                         │\n",
       "│ str                          ┆ i64   ┆ list[str]                   ┆ list[str]                   │\n",
       "╞══════════════════════════════╪═══════╪═════════════════════════════╪═════════════════════════════╡\n",
       "│ denial of normal the con be  ┆ 1     ┆ [\"denial\", \"of\", …          ┆ [\"denial\", \"normal\", …      │\n",
       "│ as…                          ┆       ┆ \"retard\"]                   ┆ \"retard…                    │\n",
       "│ just by being able to tweet  ┆ 1     ┆ [\"just\", \"by\", … \"vagina\"]  ┆ [\"able\", \"tweet\", …         │\n",
       "│ th…                          ┆       ┆                             ┆ \"vagina\"]                   │\n",
       "│ that is retarded you too     ┆ 1     ┆ [\"that\", \"is\", … \"life\"]    ┆ [\"retard\", \"cute\", …        │\n",
       "│ cute …                       ┆       ┆                             ┆ \"life\"]                     │\n",
       "│ thought of a real badass     ┆ 1     ┆ [\"thought\", \"of\", … \"be\"]   ┆ [\"think\", \"real\", … \"soon\"] │\n",
       "│ mongo…                       ┆       ┆                             ┆                             │\n",
       "│ afro american basho          ┆ 1     ┆ [\"afro\", \"american\",        ┆ [\"afro\", \"american\",        │\n",
       "│                              ┆       ┆ \"basho\"]                    ┆ \"basho\"]                    │\n",
       "│ …                            ┆ …     ┆ …                           ┆ …                           │\n",
       "│ i mute this telecasting and  ┆ 1     ┆ [\"i\", \"mute\", … \"cunt\"]     ┆ [\"mute\", \"telecast\", …      │\n",
       "│ pl…                          ┆       ┆                             ┆ \"cunt\"]                     │\n",
       "│ but hell yeah he s not a     ┆ 1     ┆ [\"but\", \"hell\", … \"singer\"] ┆ [\"hell\", \"yeah\", …          │\n",
       "│ bache…                       ┆       ┆                             ┆ \"singer\"]                   │\n",
       "│ great video musician but s   ┆ 1     ┆ [\"great\", \"video\", …        ┆ [\"great\", \"video\", …        │\n",
       "│ not…                         ┆       ┆ \"professi…                  ┆ \"professi…                  │\n",
       "│ not great pop video yeah he  ┆ 1     ┆ [\"not\", \"great\", …          ┆ [\"not\", \"great\", …          │\n",
       "│ s …                          ┆       ┆ \"singer\"]                   ┆ \"singer\"]                   │\n",
       "│ great video yeah he s non a  ┆ 1     ┆ [\"great\", \"video\", …        ┆ [\"great\", \"video\", …        │\n",
       "│ pa…                          ┆       ┆ \"singer\"]                   ┆ \"singer\"]                   │\n",
       "└──────────────────────────────┴───────┴─────────────────────────────┴─────────────────────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xcGom43esRkh"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "vector_size = model.vector_size\n",
    "vocab = set(model.wv.index_to_key)\n",
    "\n",
    "def embed_word(text, vector_size=vector_size, vocab=vocab):\n",
    "    embeddings = [\n",
    "        (model.wv[word].astype(np.float32) if word in vocab else np.zeros(vector_size, dtype=np.float32))\n",
    "        for word in text\n",
    "    ]\n",
    "    del vector_size\n",
    "    del vocab\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfHKoniNhWRe",
    "outputId": "fd49d1b2-c13c-4f07-817a-3a30a679711b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'Content': String, 'Label': Int64, 'Tokens_Content': List(String), 'Processed_Content': List(String), 'Vector_Content': List(Array(Float32, shape=(300,)))})\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "schema = {\n",
    "    'Content': pl.Utf8,\n",
    "    'Label': pl.Int64,\n",
    "    'Tokens_Content': pl.List(pl.Utf8),\n",
    "    'Processed_Content': pl.List(pl.Utf8),\n",
    "    'Vector_Content': pl.List(pl.Array(pl.Float32, 300))\n",
    "}\n",
    "\n",
    "initial_data = {\n",
    "    'Content': [\"sample text\"],\n",
    "    'Label': [1],\n",
    "    'Tokens_Content': [[\"token1\", \"token2\"]],\n",
    "    'Processed_Content': [[\"processed_token1\", \"processed_token2\"]],\n",
    "    'Vector_Content': [[[0.1] * 300]]\n",
    "}\n",
    "\n",
    "df = pl.DataFrame(initial_data)\n",
    "df = df.with_columns(\n",
    "    pl.col(\"Vector_Content\").map_elements(\n",
    "        lambda x: [np.array(i, dtype=np.float32) for i in x], return_dtype=pl.List(pl.Array(pl.Float32, 300\n",
    "                                                                                            )))\n",
    ")\n",
    "\n",
    "empty_df = df.slice(0,0)\n",
    "print(empty_df.schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "z_vuqyQioGfs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1482"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "67Pg_owssRkj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before batch processing - Memory Usage: 36.5%\n",
      "Before batch 1 - Memory Usage: 36.5%\n",
      "After processing batch 1 - Memory Usage: 55.7%\n",
      "After garbage collection for batch 1 - Memory Usage: 55.7%\n",
      "Round 1 processed\n",
      "Before batch 2 - Memory Usage: 55.7%\n",
      "After processing batch 2 - Memory Usage: 59.7%\n",
      "After garbage collection for batch 2 - Memory Usage: 59.4%\n",
      "Round 2 processed\n",
      "Before batch 3 - Memory Usage: 59.4%\n",
      "After processing batch 3 - Memory Usage: 59.5%\n",
      "After garbage collection for batch 3 - Memory Usage: 59.7%\n",
      "Round 3 processed\n",
      "Before batch 4 - Memory Usage: 59.7%\n",
      "After processing batch 4 - Memory Usage: 66.3%\n",
      "After garbage collection for batch 4 - Memory Usage: 66.1%\n",
      "Round 4 processed\n",
      "Before batch 5 - Memory Usage: 66.1%\n",
      "After processing batch 5 - Memory Usage: 51.9%\n",
      "After garbage collection for batch 5 - Memory Usage: 52.2%\n",
      "Round 5 processed\n",
      "After all batches processed - Memory Usage: 52.1%\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import psutil\n",
    "import polars as pl\n",
    "\n",
    "def print_memory_usage(message=\"\"):\n",
    "    memory = psutil.virtual_memory().percent\n",
    "    print(f\"{message} - Memory Usage: {memory}%\")\n",
    "\n",
    "batch_size = len(processed_df) // 5\n",
    "\n",
    "print_memory_usage(\"Before batch processing\")\n",
    "\n",
    "for i in range(5):\n",
    "    print_memory_usage(f\"Before batch {i+1}\")\n",
    "\n",
    "    cdf = processed_df.slice(batch_size*i, batch_size)\n",
    "    x = (cdf.lazy()\n",
    "         .with_columns(pl.col(\"Processed_Content\")\n",
    "                       .map_elements(embed_word, return_dtype=pl.List(pl.Array(pl.Float32, 300)))\n",
    "                       .alias(\"Vector_Content\"))\n",
    "         .collect())\n",
    "    empty_df.vstack(x, in_place=True)\n",
    "    print_memory_usage(f\"After processing batch {i+1}\")\n",
    "    del cdf\n",
    "    del x\n",
    "    gc.collect()\n",
    "\n",
    "    print_memory_usage(f\"After garbage collection for batch {i+1}\")\n",
    "    print(f'Round {i+1} processed')\n",
    "gc.collect()\n",
    "print_memory_usage(\"After all batches processed\")\n",
    "\n",
    "\n",
    "if len(empty_df) < len(processed_df):\n",
    "    cdf = processed_df.slice(batch_size * 5, len(processed_df) % 5)\n",
    "    x = (cdf.lazy()\n",
    "         .with_columns(pl.col(\"Processed_Content\")\n",
    "                       .map_elements(embed_word, return_dtype=pl.List(pl.Array(pl.Float32, 300)))\n",
    "                       .alias(\"Vector_Content\"))\n",
    "         .collect())\n",
    "\n",
    "    empty_df.vstack(x, in_place=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "path : pathlib.Path = \"vectorized_df.parquet\"\n",
    "\n",
    "empty_df.write_parquet(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File vectorized_df.parquet uploaded to container containerforregular/Parquet Files.\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "with open(\"keys.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "connection_string = data.get(\"Connection_string\")\n",
    "container_name = \"containerforregular/Parquet Files\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "import os\n",
    "local_file_path : pathlib.Path = \"vectorized_df.parquet\"\n",
    "blob_name = os.path.basename(local_file_path)\n",
    "\n",
    "blob_client = container_client.get_blob_client(blob_name)\n",
    "\n",
    "with open(local_file_path, \"rb\") as data:\n",
    "    blob_client.upload_blob(data, overwrite=False)\n",
    "\n",
    "print(f\"File {blob_name} uploaded to container {container_name}.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
